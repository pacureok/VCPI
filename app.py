import gradio as gr
import os
import subprocess
import torch
import gc
import numpy as np
import soundfile as sf
from audiocraft.models import musicgen
from motor_vcpi import MotorVCPI  # Importa tu clase de Panda3D

# --- LIMPIEZA INICIAL DE MEMORIA ---
def clear_vram():
    gc.collect()
    torch.cuda.empty_cache()

# --- INICIALIZACI√ìN ---
print("üöÄ Iniciando Cerebro Multimedia de Pacure AI Labs...")
clear_vram()

try:
    # Usamos musicgen-melody para seguir la identidad sonora
    music_model = musicgen.MusicGen.get_pretrained('facebook/musicgen-melody', device='cuda')
    motor = MotorVCPI()
    print("‚úÖ Modelos cargados con √©xito.")
except Exception as e:
    print(f"‚ö†Ô∏è Error en inicializaci√≥n: {e}")
    motor = None

def pipeline_maestro(prompt, duracion_seg):
    clear_vram()
    
    # 1. OLLAMA: Generaci√≥n de Guion (Identidad de IA)
    print("üß† Ollama: Redactando guion...")
    # Comando blindado para evitar errores de caracteres
    guion_cmd = f"ollama run llama3 'Escribe una frase epica y corta de exploracion para: {prompt}'"
    guion = subprocess.getoutput(guion_cmd)

    # 2. MUSICGEN: Composici√≥n de 3 Minutos (Backrooms/Cinematic)
    print(f"üéµ MusicGen: Generando {duracion_seg}s de audio...")
    music_model.set_generation_params(duration=int(duracion_seg), cfg_coef=6.0)
    
    # Prompt enriquecido para la identidad musical
    music_prompt = f"Backrooms, liminal space, {prompt}, haunting dark ambient, 60bpm, high fidelity."
    res = music_model.generate([music_prompt], progress=True)
    
    audio_wav = "banda_sonora.wav"
    audio_data = res.cpu().numpy()[0, 0] # Extraer el audio correctamente
    sf.write(audio_wav, audio_data, 32000)

    # 3. EDGE-TTS: Voz Narrativa
    print("üéôÔ∏è TTS: Generando locuci√≥n...")
    voz_mp3 = "narracion.mp3"
    texto_voz = guion.replace('"', '').replace('\n', ' ')[:500]
    os.system(f'edge-tts --text "{texto_voz}" --write-media {voz_mp3} --voice es-MX-DaliaNeural')

    # 4. MOTOR 3D: Renderizado de Escena
    print("üé• Motor 3D: Capturando render...")
    render_img = "fallback.png"
    if motor:
        try:
            render_img = motor.crear_escena(niebla_densidad=0.15)
        except Exception as e:
            print(f"Error en render: {e}")

    # 5. FFMPEG: Creaci√≥n del Video Final MP4
    print("üé¨ FFMPEG: Ensamblando pel√≠cula final...")
    video_final = "VCPI_Movie_Final.mp4"
    # El comando mezcla la imagen, la m√∫sica de fondo y la voz
    ffmpeg_cmd = (
        f'ffmpeg -loop 1 -i {render_img} -i {audio_wav} -i {voz_mp3} '
        f'-filter_complex "[1:a][2:a]amix=inputs=2:duration=first[aout]" '
        f'-map 0:v -map "[aout]" -c:v libx264 -t {duracion_seg} -pix_fmt yuv420p {video_final} -y'
    )
    subprocess.run(ffmpeg_cmd, shell=True)

    return guion, video_final, audio_wav

# --- INTERFAZ DE GRADIO (P√ÅGINA WEB) ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üåå VCPI - Hub Multimedia Aut√≥nomo")
    gr.Markdown("Control de Guion, M√∫sica (3 min), Render 3D y Voces.")
    
    with gr.Row():
        with gr.Column():
            entrada_idea = gr.Textbox(label="Instrucci√≥n a la IA", placeholder="Un monolito brillante en el vac√≠o...")
            slider_tiempo = gr.Slider(minimum=10, maximum=180, value=30, step=1, label="Duraci√≥n (Segundos)")
            btn_generar = gr.Button("üöÄ GENERAR UNIVERSO", variant="primary")
            
        with gr.Column():
            salida_guion = gr.Textbox(label="üìú Guion de Llama 3")
            salida_video = gr.Video(label="üìΩÔ∏è Pel√≠cula Renderizada (MP4)")
            salida_audio = gr.Audio(label="üéµ Banda Sonora (WAV)")

    # Conexi√≥n de inputs a outputs
    btn_generar.click(
        fn=pipeline_maestro,
        inputs=[entrada_idea, slider_tiempo],
        outputs=[salida_guion, salida_video, salida_audio]
    )

if __name__ == "__main__":
    # share=True permite abrir la web desde fuera de Kaggle
    demo.launch(share=True)
